{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "In this file, instructions how to approach the challenge can be found.\n",
    "\n",
    "We can use different types of clustering algorithms:\n",
    "\n",
    "- KMeans\n",
    "- Hierarchical\n",
    "- DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium # map visualization\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans # import k-means for clustering stage\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings # ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation of NYC neighborhoods\n",
    "\n",
    "The goal of this project is to segment the neighborhoods of New York City into separate clusters and examine the information about them. For clustering, We can use any available information **except** demographic and economic indicators. We don't want to segment them based on those and we want to keep them for the **profiling of clusters** to see if there are any important economic differences between the created clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data files\n",
    "venues_grouped = pd.read_csv('data/venues_grouped.csv')\n",
    "venues_common = pd.read_csv('data/venues_common.csv')\n",
    "lyft = pd.read_csv('data/lyftpickups.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Feature engineering plays a crucial role in this problem. We have limited amount of attributes so we need to create some features that will be important for segmentation.\n",
    "\n",
    "- Google Places, Yelp and Foursquare APIs: number of venues, density of venues per square mile, number of restaurants, top restarurant category...\n",
    "- Uber: number of rides per day in the neighborhood\n",
    "- Meetups: number of events\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lyft pickups to venues_grouped, it includes geocodes\n",
    "venues_grouped = pd.merge(venues_grouped, lyft, how='left', on=['neighborhood', 'borough'])\n",
    "venues_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for only lyft pickups\n",
    "#df = venues_grouped['lyft_pickups']\n",
    "\n",
    "# scale lyft pickups column using min-max scaling\n",
    "#scaler = MinMaxScaler()\n",
    "#df = scaler.fit_transform(df.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for venue data\n",
    "#df = venues_grouped.drop(['neighborhood', 'borough', 'latitude', 'longitude', 'lyft_pickups'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for all data\n",
    "df = venues_grouped.drop(['neighborhood', 'borough', 'latitude', 'longitude'], axis=1)\n",
    "\n",
    "# scale lyft pickups column using min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "df['lyft_pickups'] = scaler.fit_transform(df['lyft_pickups'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection / Dimensionality ReductionÂ¶\n",
    "We need to apply different selection techniques to find out which one will be the best for our problems.\n",
    "\n",
    "Original Features vs. PCA conponents?\n",
    "\n",
    "Don't forget to scale the features for KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do scree plot to see how many features are needed to explain the data\n",
    "# pca to plot the principal component weight\n",
    "pca = PCA()\n",
    "pca.fit(df)\n",
    "pca_data = pca.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "# only first 10\n",
    "per_var = per_var[:10]\n",
    "labels = ['PC' + str(x) for x in range (1, len(per_var)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('Percentage of Explained Variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Scree Plot of first 10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "1. Check the segmentation evaluation metrics:\n",
    "    - inertia\n",
    "    - silhoutte score\n",
    "2. How did you come up with the correct number of clusters?\n",
    "3. Is there any relationship between the clusters and economic indicators? If yes, what does it mean?\n",
    "\n",
    "You are required to share the file containing all NYC neighborhoods together with cluster_id with LighthouseLabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot distortion of kmeans clustering\n",
    "def plot_distortion(X,max_clusters = 10):\n",
    "    distortions = []\n",
    "    for i in range(1, max_clusters +1):\n",
    "        km = KMeans(n_clusters=i,\n",
    "                    init='k-means++',\n",
    "                    n_init=10,\n",
    "                    random_state=0)\n",
    "        km.fit(X)\n",
    "        distortions.append(km.inertia_)\n",
    "\n",
    "    plt.plot(range(1,max_clusters +1), distortions, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inertia, elbow rule\n",
    "plot_distortion(df, max_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get silhouette score\n",
    "sil = []\n",
    "K_sil = range(2,10)\n",
    "# minimum 2 clusters required, to define dissimilarity\n",
    "for k in K_sil:\n",
    "    print(k, end=' ')\n",
    "    kmeans = KMeans(n_clusters = k).fit(df)\n",
    "    labels = kmeans.labels_\n",
    "    sil.append(silhouette_score(df, labels, metric = 'euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K_sil, sil, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('silhouette_score')\n",
    "plt.title('Silhouette Method For Optimal k')\n",
    "plt.savefig('silo.png')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('silo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Use different attributes and clustering techniques and compare the created clusters:\n",
    "\n",
    "- clustering only on restaurant features\n",
    "- clustering only on Uber features\n",
    "- clustering only on location\n",
    "- combination of all\n",
    "\n",
    "**Questions:**\n",
    "1. Which clustering is the best?\n",
    "2. How are neighborhoods split when we select only 2 clusters?\n",
    "3. Are there any differences in housing and rental costs in different clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca based on scree plot\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do Kmeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42).fit(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kmeans cluster labels to venues grouped dataframe\n",
    "venues_grouped['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new york latitude and longitude\n",
    "latitude = 40.7128\n",
    "longitude = -74.0060\n",
    "\n",
    "\n",
    "# create a map to display clusters\n",
    "def color_clust(cluster):\n",
    "    if cluster == 0:\n",
    "        return 'green'\n",
    "    elif cluster == 1:\n",
    "        return 'blue'\n",
    "    elif cluster == 2:\n",
    "        return 'red'\n",
    "    elif cluster == 3:\n",
    "        return 'yellow'\n",
    "    elif cluster == 4:\n",
    "        return 'orange'\n",
    "    elif cluster == 5:\n",
    "        return 'purple'\n",
    "\n",
    "\n",
    "map_newyork_clusters = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# add color coded cluster circles to map\n",
    "for hood, lat, lng, label in zip(venues_grouped['neighborhood'], venues_grouped['latitude'], venues_grouped['longitude'], venues_grouped['cluster']):\n",
    "    nodename = '{}, {}'.format(label, hood)\n",
    "    folium.Circle(location=[lat, lng],\n",
    "    stroke=False, \n",
    "    fill_color=color_clust(label),\n",
    "    radius=900,\n",
    "    fill_opacity=0.6,\n",
    "    tooltip=nodename).add_to(map_newyork_clusters)\n",
    "\n",
    "# change map save location for different clusters\n",
    "map_newyork_clusters.save('data/clusters_all.html')\n",
    "map_newyork_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe with each neighborhoods top 10 venues\n",
    "num_top_venues = 10\n",
    "\n",
    "columns = ['cluster']\n",
    "for i in range(num_top_venues):\n",
    "    columns.append(str(i+1) + ' common')\n",
    "\n",
    "cluster_common_venues = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "venues_common['cluster'] = kmeans.labels_\n",
    "# unique cluster labels\n",
    "labels = set(kmeans.labels_)\n",
    "\n",
    "# get common venues for each cluster\n",
    "for label in labels:\n",
    "    row = [label]\n",
    "    for venue in range(1, 11):\n",
    "        topvenue = venues_common.query('cluster == {}'.format(label))['{} common'.format(venue)].value_counts().index.to_list()[0]\n",
    "        row.append(topvenue)\n",
    "    # add row to dataframe\n",
    "    cluster_common_venues = cluster_common_venues.append(pd.DataFrame([row], columns=columns), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print common venues grouped by cluster\n",
    "cluster_common_venues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Tried kmeans on just lyft data, just venue data and both together.\n",
    "- Lyft rides data really dominates as a principal component and clusters change"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a3c54e841fe8ed729f88f1a4dbf5907a70c4a9986278aeeef34dd666b803d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
